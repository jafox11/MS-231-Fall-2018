{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Gradient Descent Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following function will execute the gradient descent method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def gradient_descent(f, init_x, init_y, rate, tolerance):\n",
    "    X = vector((init_x, init_y))\n",
    "    grad = vector((diff(f, x), diff(f, y)))\n",
    "    difference = 1\n",
    "    while difference > tolerance:\n",
    "        X_old = X\n",
    "        X = X_old - rate * grad(x = X_old[0], y = X_old[1])\n",
    "        difference = (X_old - X).norm()\n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Define $x$ and $y$ as variables and then enter the function $f$ that you would like to optimize, the $x$- and $y$-values of the initial guess, the learning rate, and the tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "x, y = var('x y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "f = x^2 + y^2\n",
    "init_x = 2\n",
    "init_y = 3\n",
    "rate = 0.05\n",
    "tolerance = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now call the function with your chosen parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00493006940991613, 0.00739510411487420)"
      ]
     },
     "execution_count": 21,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(f, init_x, init_y, rate, tolerance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath (stable)",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}